{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom-multiple-signatures-mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o95xdcCUhdlL"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the constants\n",
        "IMAGE_SIZE = [28, 28]\n",
        "BATCH_SIZE = 128\n",
        "INPUT_SHAPE = (28, 28, 1)\n",
        "TRAIN_RATIO = 0.75\n",
        "\n",
        "NUM_EPOCHS = 5"
      ],
      "metadata": {
        "id": "vhPOB_cP05cm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to split train dataset into train and validation\n",
        "def _split_train_val(train_data, train_ratio=0.8):\n",
        "    # getting the size\n",
        "    image_count = train_data.cardinality().numpy()\n",
        "\n",
        "    # shuffling the data\n",
        "    train_data = train_data.shuffle(buffer_size=10000)\n",
        "\n",
        "    # splitting\n",
        "    dataset_train = train_data.take(image_count * train_ratio)\n",
        "    dataset_validation = train_data.skip(image_count * train_ratio)\n",
        "    \n",
        "    return dataset_train, dataset_validation\n",
        "\n",
        "# to rescale and resize the images\n",
        "def _resize_scale_image(image, label, image_size=IMAGE_SIZE):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    image = image/255.\n",
        "    return image, label\n",
        "\n",
        "def get_datasets():\n",
        "    # loading the dataset\n",
        "    train_data, test_data = tfds.load(name=\"mnist\", split=(\"train\", \"test\"), as_supervised=True)\n",
        "    \n",
        "    dataset_train, dataset_validation = _split_train_val(train_data, train_ratio=TRAIN_RATIO)\n",
        "    dataset_test = test_data\n",
        "\n",
        "    print(\"Number of samples in train: \", dataset_train.cardinality().numpy())\n",
        "    print(\"Number of samples in validation: \", dataset_validation.cardinality().numpy())\n",
        "    print(\"Number of samples in test: \", dataset_test.cardinality().numpy())\n",
        "\n",
        "    # applying the rescale function\n",
        "    dataset_train = dataset_train.map(_resize_scale_image)\n",
        "    dataset_validation = dataset_validation.map(_resize_scale_image)\n",
        "\n",
        "    # creating batches and prefetches\n",
        "    dataset_train = dataset_train.batch(BATCH_SIZE)\n",
        "    dataset_train = dataset_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    dataset_validation = dataset_validation.batch(BATCH_SIZE)\n",
        "    dataset_validation = dataset_validation.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset_train, dataset_validation, dataset_test\n",
        "\n",
        "training_set, validation_set, testing_set = get_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ-BrejYugaE",
        "outputId": "0e5992e4-5188-4981-8557-fa6d308e50ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train:  45000\n",
            "Number of samples in validation:  15000\n",
            "Number of samples in test:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model\n",
        "def get_model():\n",
        "    # defining the model\n",
        "    model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=INPUT_SHAPE, name=\"image\"),\n",
        "                                tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "                                tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "                                tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "                                tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "                                tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "                                tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                tf.keras.layers.Dense(10, activation=\"softmax\", name=\"softmax_output\")\n",
        "    ])\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiKDbCFZmzRC",
        "outputId": "3ec5130b-6f17-49fb-fd2b-2a547883e330"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " image (Conv2D)              (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 128)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " softmax_output (Dense)      (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,962\n",
            "Trainable params: 93,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling and training the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(training_set, \n",
        "          validation_data = validation_set, \n",
        "          epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5SFQ6Y9pMAx",
        "outputId": "07db61b3-a641-4dd0-db4e-3f48b9713867"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "352/352 [==============================] - 17s 41ms/step - loss: 0.3521 - accuracy: 0.8955 - val_loss: 0.1402 - val_accuracy: 0.9570\n",
            "Epoch 2/5\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1014 - accuracy: 0.9690 - val_loss: 0.0840 - val_accuracy: 0.9734\n",
            "Epoch 3/5\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0720 - accuracy: 0.9781 - val_loss: 0.0851 - val_accuracy: 0.9755\n",
            "Epoch 4/5\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0605 - accuracy: 0.9807 - val_loss: 0.0602 - val_accuracy: 0.9813\n",
            "Epoch 5/5\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0487 - accuracy: 0.9842 - val_loss: 0.0469 - val_accuracy: 0.9857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the performance on the test set\n",
        "results = model.evaluate(testing_set.batch(BATCH_SIZE), verbose=2)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "    print(f\"{name}: {round(value, 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70gkfCk2pLJb",
        "outputId": "b196659a-83c6-428e-eb1e-b34e481b74ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 - 1s - loss: 13.9706 - accuracy: 0.9751 - 1s/epoch - 18ms/step\n",
            "loss: 13.971\n",
            "accuracy: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting some images from the test set to visualize the raw predictions\n",
        "images = []\n",
        "labels = []\n",
        "for image, label in testing_set.take(10):\n",
        "    images.append(image.numpy())\n",
        "    labels.append(label.numpy())\n",
        "\n",
        "softmax_result = model.predict(x=tf.constant(images))\n",
        "print(softmax_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD_JYJUy5O4U",
        "outputId": "6eb41975-f823-4677-b547-58d635e34b29"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting the model\n",
        "import os\n",
        "import datetime\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "export_path = Path(\"models\")\n",
        "model_path = export_path / \"default\" / \"mnist_{}\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l1poe5R6MxQ",
        "outputId": "7b0f5c8c-5d5b-42a7-c274-0480934850de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/default/mnist_20220112_135012/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/default/mnist_20220112_135012/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see the files in the saved models\n",
        "!find models/default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBD2cCGe6_gP",
        "outputId": "4fc70f70-f416-4cb7-c257-50be9f12464e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/default\n",
            "models/default/mnist_20220112_133734\n",
            "models/default/mnist_20220112_133734/saved_model.pb\n",
            "models/default/mnist_20220112_133734/variables\n",
            "models/default/mnist_20220112_133734/variables/variables.index\n",
            "models/default/mnist_20220112_133734/variables/variables.data-00000-of-00001\n",
            "models/default/mnist_20220112_133734/keras_metadata.pb\n",
            "models/default/mnist_20220112_133734/assets\n",
            "models/default/mnist_20220112_135012\n",
            "models/default/mnist_20220112_135012/saved_model.pb\n",
            "models/default/mnist_20220112_135012/variables\n",
            "models/default/mnist_20220112_135012/variables/variables.index\n",
            "models/default/mnist_20220112_135012/variables/variables.data-00000-of-00001\n",
            "models/default/mnist_20220112_135012/keras_metadata.pb\n",
            "models/default/mnist_20220112_135012/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see the prediction meta-data about the trained model\n",
        "!saved_model_cli show --dir {model_path} --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXYtau17I4k",
        "outputId": "2d5f249c-9a65-41d4-b5f9-ebc3c06f4605"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['image_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_image_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['softmax_output'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can see that it takes an image and returns the softmax score for the ten classes\n",
        "restored = tf.keras.models.load_model(model_path)\n",
        "infer = restored.signatures[\"serving_default\"]\n",
        "outputs = infer(image_input=tf.constant(images, dtype=tf.float32))\n",
        "softmax_outputs = outputs[\"softmax_output\"]\n",
        "print(softmax_outputs, end=\"\\n\\n\")\n",
        "\n",
        "# if we want the final results, \n",
        "# we would need to convert the results in to argmax for each result\n",
        "print(tf.math.argmax(softmax_outputs, axis=1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw2M1V2H72VR",
        "outputId": "21087e8c-e5e3-4429-9ff0-cc02800f0890"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "\n",
            "[2 0 4 8 7 6 0 6 3 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now considering we are serving two different clients,\n",
        "# one may require the final results while the other may require the softmax results as well.\n",
        "\n",
        "# creating the default signature which outputs only the final classes\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\n",
        "def final_classes(images):\n",
        "    softmax_outputs = model(images, training=False)\n",
        "    final_classes = tf.math.argmax(softmax_outputs, axis=1)\n",
        "    return {\n",
        "        \"outputs\": final_classes\n",
        "    }\n",
        "\n",
        "# the secondary signature that returns both outputs\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32)])\n",
        "def add_final_classes(images):\n",
        "    softmax_outputs = model(images, training=False)\n",
        "    final_classes = tf.math.argmax(softmax_outputs, axis=1)\n",
        "    return {\n",
        "        \"softmax_outputs\": softmax_outputs,\n",
        "        \"outputs\": final_classes\n",
        "    }\n",
        "\n",
        "shutil.rmtree(export_path / \"final_classes\", ignore_errors=True)\n",
        "final_export_path = export_path / \"final_classes\" / \"mnist_{}\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "model.save(final_export_path, signatures={\"serving_default\": final_classes, \"serving_with_softmax\": add_final_classes})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-lnj-_9whs",
        "outputId": "7fbcda1e-95d4-47e4-e985-4396bdf35002"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/final_classes/mnist_20220112_135018/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/final_classes/mnist_20220112_135018/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can now see that the default signature would give only the final classes\n",
        "!saved_model_cli show --dir {final_export_path} --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLVHODhqiDaW",
        "outputId": "90fd6908-72dd-4f17-e777-6f9ef6091ff1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['images'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_images:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['outputs'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can now see that the secondary signature would give both the outputs\n",
        "!saved_model_cli show --dir {final_export_path} --tag_set serve --signature_def serving_with_softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dneccQcAtiE",
        "outputId": "84a20b89-ebc8-42fd-ef21-fba26d929716"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['images'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_with_softmax_images:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['outputs'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:0\n",
            "  outputs['softmax_outputs'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall_1:1\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serving 1 (only final classes)\n",
        "print(\".: Serving serving_default :.\\n\")\n",
        "restored = tf.keras.models.load_model(final_export_path)\n",
        "infer = restored.signatures[\"serving_default\"]\n",
        "outputs = infer(images=tf.constant(images, dtype=tf.float32))\n",
        "outputs = outputs[\"outputs\"]\n",
        "print(outputs.numpy(), end=\"\\n\\n\")\n",
        "\n",
        "# serving 2 (with softmax outputs)\n",
        "print(\".: Serving serving_with_softmax :.\\n\")\n",
        "restored = tf.keras.models.load_model(final_export_path)\n",
        "infer = restored.signatures[\"serving_with_softmax\"]\n",
        "outputs = infer(images=tf.constant(images, dtype=tf.float32))\n",
        "outputs_softmax = outputs[\"softmax_outputs\"]\n",
        "outputs = outputs[\"outputs\"]\n",
        "print(outputs_softmax.numpy(), end=\"\\n\\n\")\n",
        "print(outputs.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmeJegtQGACV",
        "outputId": "1b8acacf-5133-41a8-903f-9d5177918c73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: Serving serving_default :.\n",
            "\n",
            "[2 0 4 8 7 6 0 6 3 1]\n",
            "\n",
            ".: Serving serving_with_softmax :.\n",
            "\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "[2 0 4 8 7 6 0 6 3 1]\n"
          ]
        }
      ]
    }
  ]
}